---
title: "Jared's Models"
author: "Jared Colbert"
date: "11/30/2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(leaps)
purple = '#772299'; green = '#3FE500'
red = '#E50000'; lightblue = '#229999';
blue = '#336699'
```

```{r}
knees = read.csv('knees.csv')
knees$Surgeon = as.factor(knees$Surgeon)
knees$Year = as.factor(knees$Year)
```

```{r}
plots = function(model) {
  par(mfcol=c(2,2))
  qqnorm(resid(model), col = red, pch = 16)
  qqline(resid(model), col = lightblue, lwd = 2)
  
  plot(fitted(model), resid(model), xlab = 'Fitted Values', ylab = 'Residuals', main = 'Fitted vs. Residuals Plot', col = purple, pch = 16)
  abline(h = 0, col = green, lwd = 2)
  
  hist(resid(model), col = blue, main = 'Histogram of Residuals', xlab = 'Residuals')
}

evaluate = function(model){
  
  # Run each of the tests
  shapiroTest = shapiro.test(resid(model))
  bpTest = bptest(model)
  rSquared = summary(model)$r.squared
  adjRSquared = summary(model)$adj.r.squared
  loocv = sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
  large_lev = sum(hatvalues(model) > 2 * mean(hatvalues(model)))
  # gives percentage of large residuals (should be less than 5%)
  large_resid = sum(rstandard(model)[abs(rstandard(model)) > 2]) / length(resid(model)) 
  
  # Collect tests in dataframe
  values = data.frame(Result = c(prettyNum(shapiroTest$p.value), prettyNum(bpTest$p.value), prettyNum(rSquared), prettyNum(adjRSquared),        prettyNum(loocv), prettyNum(large_lev), prettyNum(large_resid))) 
  rowNames = data.frame(Test = c('Shapiro Wilk pvalue', 'Breusch-Pagan pvalue', 'R Squared', 'Adj R Squared', 'Cross Validation', 'Large Leverages', 'Large Residuals'))

  summary_output = cbind(rowNames, values)
  # Add dataframe to matrix
  show(summary_output)
  plots(model)
}

removeLargeHatValues = function(model, data){
  values = hatvalues(model)
  index_ = which(values > (2 * mean(values)))
  newData = data[-c(index_),]
  return(newData)
}
```


```{r}
## BruteForce Model (glmulti)
model_one = lm(KneeScore_Patient~1+Age:Year+Weight:Age+Height:Year+Height:Age+Height:Weight+BMI:Age+KneeScore_Surgeon:BMI+TibialInsertWidth:Year+TibialInsertWidth:KneeScore_Surgeon+PatellaDiameter:Age+PatellaDiameter:Height+PatellaDiameter:TibialInsertWidth, data = knees)
evaluate(model_one)
```

```{r}
model_two = lm(KneeScore_Patient ~ ., data = knees)
evaluate(model_two)
```

**There are 181 large leverage points in this model - Remove the large leverages and refit**

```{r}
new_data = removeLargeHatValues(model_two, knees)
model_three = lm(KneeScore_Patient ~ ., data = new_data)
evaluate(model_three)
```

**remove again and refit**

```{r}
new_data_two = removeLargeHatValues(model_three, new_data)
model_four = lm(KneeScore_Patient ~ ., data = new_data_two)
evaluate(model_four)
```

**That's not working.  Try a transformation of the response**
Log transformation causes some values to be `-Inf` because that value is 0.  Replace all zeros with the mean of the column.

```{r}
# replace all 0 values with the mean of the vector
temp = knees
temp$KneeScore_Patient[temp$KneeScore_Patient == 0] = mean(temp$KneeScore_Patient)

model_five = lm(KneeScore_Patient ~ ., data = temp)
evaluate(model_five)
```

Approaches that are not working:
1. Transformations of response

```{r}
model_six = lm(KneeScore_Patient ~ Surgeon * Side, data = knees)
evaluate(model_six)
```

```{r}
model_two_bic = step(model_two, direction = "backward", trace = 0, k = log(nrow(knees)))
evaluate(model_two_bic)
```

